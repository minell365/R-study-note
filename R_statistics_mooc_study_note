데이터로 배우는 통계학 mooc 강의

##6-1 최소제곱법

회귀모형-우리 집 가격은 얼마지?
회귀분석 -> 예측, 두 모형사이의 관계를 예측하기 위한 것(=두 변수 간의 관계를 모형화하는 방법)
            특히 한 변수를 이용하여 다른 변수를 예측하거나 설명하는데 유용
            
설명변수와 반응변수
반응변수(=종속변수) : 우리가 설명하거나 예측하고 싶은 변수
설명변수(=독립변수) : 반응변수의 값을 예측하기 위해 사용되는 변수

잔차(residual) : 추정치와 실제값의 차이, 오차항의 추정치, 추정치와 실제값과 수직거리 차이


##6-2 회귀모형의 진단

회귀모형 : 오차항은 서로 독립, 평균은 0, 분산은 ~~인 정규본포
회귀모형을 데이터에 적합 시키기 위해서 가정이 필요 
-> 반응변수와 설명변수간의 선형관계
-> 반응변수의 등분산성
-> 반응변수의 정규분포
-> 반응변수값의 독립

반응변수와 설명변수 관계가 선형일 경우 회귀분석을 사용할 수 있음
선형여부에 관한 판단 -> 산점도 또는 잔차 그림(residual plot)을 통해서 파악

비선형 모형의 사례 -> 에볼라 발생 건수 사례

전염병 감염건수와 같이 기하급수적으로 증가하는 자료 -> 반응변수에 로그값을 취한 후 다시 회귀분석에 적합시킴
                                                       y 값을 로그스케일로 하는 경우

로그변환 하는 경우
-> 반응변수 값에 0 이 포함된 경우 0 에 아주 작은 숫자를 더한 후 로그변환
-> 반응변수와 설명변수 모두 로그변환 하는 경우

등분산성 
-> 각 반응변수의 분산은 동일하다는 가정
-> 설명변수의 값이 증가함에 따라 반응변수의 분산이 증가하는 경향
-> 반응변수를 로그 변환 또는 제곱근 변환 등을 고려
-> 변환을 하지 않는다면 가중회귀모형을 고려

정규성 가정 (-> 맨 마지막에 체크, 등분산성 먼저 체크)
-> 반응변수가 정규분포를 따름 = 오차항이 정규분포를 따름
-> 잔차들의 히스토그램을 통해 정규성 과정 확인
-> 아주 극단적으로 치우친 분포가 아니라면 회귀분석을 적합하여도 큰 문제 없음

독립성 가정
-> 반응변수 값이 서로 의존하는 경우 예)주가지수와 같은 시계열 자료
-> 연속되는 반응변수들의 값이 서로 강한 상관관계인 경우 회귀모형 사용 불가, 시계열 자료 분석을 위한 통계모형 사용


##6-3 회귀모형의 함정

평균으로의 회귀(regression to the mean)

외삼법 : 주어진 자료의 범위 밖에서 모형을 이용하여 예측하는 것

Anscombe's quartet

회귀분석에서 이상점 : 대부분의 데이터와 떨어져 있는 점, 설명변수에서의 잔차값
                    이걸 포함해서 구할 것인가 제외하고 구할 것인가
                    
이상점의 역할 : high leverage point, 회귀직선의 기울기에는 영향을 미치지는 않지만 대부분의 데이터의 중심에서 수평적으로 떨어져 있음
                influential point, 회귀직선의 기울기에 영향을 주는 점
                
   
##6-4 사례연구 2000년 미국 대선 데이터

library(UsingR)  #UsingR 패키지에 내장된 florida 데이터 셋 사용
attach(florida)
summary(florida)

result.lm <- lm(BUCHANAN ~ BUSH)
plot(BUSH, BUCHANAN)
abline(result.lm)

summary(result.lm)

기울기가 0인지 여부
Multiple R-squared 값 : 0.3889를 제시하고 잇음 -> 반응변수의 변동(분산) 중 39%를 이 회귀모형으로 설명할 수 있다는 것을 의미

#회귀직선과 떨어진 2개의 점이 어느 카운티에 해당하는지 알고 싶을때 (n=2)
with(florida, identify(BUSH, BUCHANAN, n=2, labels=County))
위 명령어 이후 마우스커서를 해당 점에 이동시킨 후 2개의 점을 모두 클릭하면 이름이 나타남

#회귀모형 진단을 위한 4개의 그림 제공, 왼쪽 상단의 잔차 vs 반응변수의 추정치의 산점도로 선형관계 가정에 대한 검증 가능
par(mfrow=c(2,2))
plot(result.lm)


##7-1 알고리즘과 인공지능


알고리즘
머신러닝

지도학습 : 분류, 예측

강인공지능, 약인공지능

빅데이터의 2가지 유형 
길쭉한 자료 : n이 큰 경우(표본 크기가 큰 경우)
뚱뚱한 자료 : p가 큰 경우(parameter의 개수가 많은 경우)  예)마이크로 어레이

과적합과 bias-variance trade-off 
주어진 데이터를 모두 사용하여 모형을 적합시킨다면 과적합이 생길 수 있음
복잡한 모형을 적합할 경우 예측치의 편의는 줄어들지만 분산은 늘어나고(=과적합이 발생), 
단순한 모형을 적합할 경우 반대 현상
따라서 적절한 모형을 적합시켜서 과적합을 피해야

훈련자료, 평가자료, 검증자료
과적합을 피하기 위한 방안으로는 전체데이터를 훈련자료(training data)와 평가자료(test data)로 나눈 후 
훈련자료를 이용하여 분석모형을 정하고 자안한 방법의 평가를 위한 평가자료를 이용

모형의 복잡도를 결정하기 위해서 별도의 검증자료(validation data)를 사용하거나 훈련자료를 활용하는 교차 검증 방법

사례연구 : 타이타닉 -> 의사결정나무를 이용한 생존률 

의사결정나무 : 가장 단순한 형태의 알고리즘 중 하나 


##7-2 알고리즘 성능평가 (<- 다시 듣기!)

정확도, 민감도, 특이도

Confusion Matrix 표

ROC 곡선 : 분류기준값에 따른 특이도와 민감도를 제시하는 그림
기준점을 상향 조정하면 특이도 증가, 민감도 감소

ROC 곡선의 비교와 AUC(ROC곡선 아래면적)

보정그림(Calibration Plot) : 확률예측이 얼마나 정확했는지 알아보기

브라이어 지수(Brier Score)
기술 지수(Skill Score)



##7-3 과적합과 알고리즘의 문제점

의사결정나무에서 계속 조걱을 추가할 경우 마지막 끝마디의 개수가 증가
-> 모형의 복잡도가 증가하면서 과적합이 일어남

교차검증 : 과적합을 피하기 위해 적절한 복잡도를 가진 모형을 선택
           훈련자료와 별도로 모형의 복잡도를 결정하기 위한 검증자료가 별도로 필요
      
조절모수(tunning parameter) : 모형의 복잡도를 결정. 
      각 다른 조절모수의 값을 이용해서 검증자료에서 예측오차를 계산한 후 그 중 가장 작은 예측오차를 제공하는 조절모수를 선택
   예) 의사결정나무 -> 조절모수는 가지(조건)의 갯수
   
K-fold 교차검증 : 1개의 교차자료만으로 조절모수를 결정할 경우의 위험성
                  이를 보완하기 위해 사용하는 방법 (k=5개나 10개를 많이 사용)
                  
그 외 다양한 분류방법들 : KNN, 랜덤 포레스트, 뉴럴 네트워크, SVM 등

알고리즘 문제 : Robustness 이슈, 변동성에 대한 고려, 내재적 편향성, 투명성, 등

Robustness 이슈 : 구글독감예측 사례
                       -> 사람들이 독감증상이 있는 경우 독감관련 검색을 하므로 검색량을 이용해서 독감환자 예측
                   처음엔 잘 맞았지만 2013년 2배 넘게 예측하면서 신뢰도 하락
                   조금의 변화에도 민감하게 예측치가 변화할 수 있음 
                         -> 모든 환경이 똑같이 유지되지 않고 구글 자체 검색엔진의 지속적 변화를 감지 못함
                   
변동성에 대한 고려 : 암발생률 지도 -> 최상위, 최하위는 주로 작은 군
                      인구가 작아 변동성이 큼
                   작은 숫자에 기반한 예측치는 변동의 가능성이 크다는 점 고려해야
                   
내재적 편향성 : 시베리아 허스키견과 늑대사진으로 분류 훈련된 인식 알고리즘이 반려견으로 길러진 허스키견을 분별 못함
                        -> 알고리즘이 사실 배경의 눈을 기준으로 구별하고 있었던 사실이 밝혀짐
                알고리즘은 연관성을 기반하기 때문에 실제 관심사항에 무관한 특징을 사용할 수 없음
                
투명성 여부 : 미국법정 범죄재발예측 알고리즘을 이용하여 계산된 위험지수를 보호관찰, 형량에 참고
               -> 알고리즘 방식 알려져 있지 않음, 다만 양육환경, 과거범죄연류 정보 사용한다고 알려짐
               -> 빈곤층의 위험지수가 높아질 가능성
             
Reverse-engineering : 투명성 부족을 해결하기 위한 방안 예)자동차보험에서 성별차별


##7-4 사례연구 : 타이타닉 (캐글)

1. 데이터 전처리
2. 의사결정나무 적합
3. Confusion Matrix와 ROC 곡선을 이용한 결과 평가
4. 분석에 사용된 코드
   https://www.kaggle.com/thilakshasilva/predicting-titanic-survival-using-five-algorithms

5. 수업에 사용된 코드 
   https://github.com/wcjang/K-MOOC/blob/main/Lab07/Lab07.Rmd



##8-1 붓스트랩(Bootstrap)

표본의 크기가 커질수록 표본의 히스토그램이 모집단의 히스토그램과 비슷해짐을 알 수 있음

통계량의 분포(표본분포 : Sampling Distribution)
같은 크기의 표본을 다시 뽑는다면 요약치의 값들이 변할 것
표본의 크기가 커질수록 표본 요약치(통계량, statistics)의 값들이 모집단의 요약치(모수, parameter)에 가까워지짐
-> 대신 각 표본 요약치의 변동성 설명은? 

요약치의 변동성(통계량의 분산)을 알아내기 위해서 모집단에서 표본크기 N이 같은 여러 개의 표본을 생성하면 됨
예) n=10인 표본을 100개 구한 후 각 표본에서 평균을 구함
            100개의 평균의 히스토그램을 그리면 n=10 인 경우 변동성을 알 수 있음
            
모집단의 요약치를 알지 못하면서 그 외의 추가정보를 아는 경우 거의 없음
-> 통계이론을 바탕으로 모집단에 관한 추가정보를 알아낼 수 있음
-> 쉽게 통계량의 변동성을 알아내는 방법은?

표본을 모집단이라 생각하고 표본에서 복원추출로 같은 크기의 재표본을 뽑음

붓스트랩을 이용한 회귀분석


##8-2 확률과 기원과 법칙

기대돗수나무(Expected Frequency Tree)
확률나무(Probablity Tree) 

확률의 법칙 : 여사건의 법칙, 덧셉법칙, 곱셈법칙

슈발리에 드 메레


##8-3 조건부 확률과 확률변수

사례연구) 유방촬영술(맘모그랩)은 언제부터 받아야 하나?

검사의 오류(Prosecutor's Fallacy) 
-> 암에 걸렸을때 진단 결과가 양성일 확률은 90%이지만 진단결과가 양성일 때 암에 걸려있을 확률은 8%
-> 현신을 이 두가지를 혼동하는 경우 많음
-> 법정에서 DNA증거에 관해서 논할때? DNA가 일치할 확률 vs 피고가 결백할 확률

고전적 확률(classical probability)
나열 확률(enumerative probability)
장기빈도확률(long-run frequency probability) : 하지만 모든 사건이 반복적으로 일어나지 않음
성향(propensity) : 특정 사건이 일어날 진짜 가능성, 이걸 알아내는건 거의 불가능
주관적 확률(subjective probability) 

확률변수란? : 표본공간에 속한 각각의 원소에 특정 숫자를 대입한 값
표본공간 : 특정 사건의 가능한 모든 결과물

베르누이 분포 : 2가지 가능한 결과물을 가진 확률변수의 확률분포

사례연구) 하루에 살인사건이 7번씩이나 일어났다고?
포아송 분포 : 시공간이 정해진 상황에서 일어나는 사건의 횟수 
              어떤 사건이 일어날 기회는 엄청나게 많지만 각 사건이 일어날 가능성이 아주 적은 경우
              모수는 평균 하나만 있음 -> 평균만 알면 이 분포의 형태를 알 수 있음
=> 하루에 7건 이상 일어날 확률은 0.07$, 4년에 한번 정도 일어날 수 있다는 의미


##8-4 사례연습 : 붓스트랩과 다양한 확률분포

R을 이용하여 다양한 확률분포의 모양 파악, 확률변수 생성 가능
mean평균, sd표준편차
확률밀도함수 : dnorm(x, mean, sd)
누적밀도함수 : pnorm(q, mean, sd)
누적밀도함수의 역함수 : qnorm(p, mean, sd)
rnorm ??

예) 수능 점수 1등급(96%) 컷 점수는?
qnrom(0.96, means=50, sd=10)

내 표준점수가 64점이라면?
pnorm(64, means=50, sd=10)


포아송 분포
확률밀도함수 : dpois(x, lambda)
누적밀도함수 : ppois(q, lambda)
n개의 정규분포를 따르는 확률변수 생성 : rpois(n, lambda) 
누적밀도함수의 역함수 : qpois(p, lambda)

예) 커플 1.3회 키스, 한시간 2회 이상 할 경우 
1-ppois(1, lambda=1.3)

평균 1.3인 포아송 분포의 확률밀도함수
x <- c(0:10)
plot(x, dpois(x, lambda=1.3), type="h")


##9-1 중심극한정리 (신뢰구간과 가설검정)

1. 탐색적 자료분석
2. 확증적 자료분석 : 자료에 관한 수치적 요약치 제시
=> 통계량 : 표본에 따라서 값이 다르게 나올 수 있기 때문에 표본분포를 아는 것이 중요
   표본분포를 알아내기 위해 1. 붓스트랩 2. 통계이론 사용
   
표본비율 : 확률변수들의 평균, P햇

이항분포 : 베르누이 분포를 확장한 경우
베르누이 분포를 n번 시행한다고 가정하면 이 경우 성공횟수의 분포가 이항분포를 따름

이항분포에서의 평균
표본비율
표준오차 : 통계량의 표준 편차

표본크기가 커질수록 이항분포가 대칭적으로 가까워지고 가운데로 집중

예) 지역별 대장암 사망률은 왜 차이가 큰가
-> 인구가 적은 지자체는 약간의 변동만 있더라도 사망률에 큰 차이
-> control limit : 각 지자체에 사망자 숫자가 이항분포를 따른다는 사실에 기반하여 그림

대수의 법칙(큰 수의 법칙) : 표본 크기가 커짐에 따라 표본비율이 평균근처로 점차 좁혀짐
수학자 베르누이에 의해 확립된 대수의 법칙 설명가능

도박사의 오류

중심극한정리 : 표본평균들도 표본크기가 증가하면 분포의 형태가 정규분포 모양을 갖게 됨


##9-2 신뢰구간 (이해가 잘 안된다!)

통계량의 불확실성 : 표준오차(통계량의 표준편차) 또는 신뢰구간을 통해 제시

95% 신뢰구간의 의미 : 
여론조사에서 95% 신뢰구간의 의미 : 

영국에서 살인사건은 계속 증가하고 있는가?


##9-3 "무죄"가 아니라 "유죄라고 할 수 없다"가 맞다

PPDAC 에서 analysis
-> 통계적 가설검정을 사용할 것

가설검정 
반응변수와 예측변수 사이에 선형관계에 대한 가정을 하거나 혹은 오차항에 대해 정규성, 등분산성, 독립성 등에 대한 가정

1. 가설검정 
  1) 귀무가설 : 현 상태에 대한 잠정적 가정
  2) 대립가설 : 우리가 알고 싶은 것
2. 검정통계량
3. 검정통계량의 표본분포
4. 결론

법정시스템 vs. 통계적 가설검정
무죄추정원칙 -> 귀무가설과 동일
법정에서 검사 : 여러 증거를 통해서 피고인이 무죄라면 이러한 증거를 확보하기 힘들것이라는 점을 강조하여 피고인이 유죄임을 입증

법정에서의 결론 : 유죄(guilty), 유죄가 아니다(not guilty)

법정에서는 무죄라는 결론을 내리지 않음 -> 유죄라고 할만한 충분한 증거가 없다는 것(not guilty)

통계적 가설검정에서도 귀무가설이 참이라는 결론은 내리지 않음
-> 대립가설이 참이거나(귀무가설 기각) 또는 대립가설이 참이라고 할 만한 충분한 증거가 없다(귀무가설을 기각할 수 없다)는 것이 결론


##9-4 사례연구 

이항분포

확률밀도함수 : dbinom(x, n, prob)
누적밀도함수 : pbinom(q, n, prob)

n개의 이항분포를 따르는 확률변수 생성 : rbinom(n, prob)

누적밀도함수의 역함수 : qbinom(p, n, prob)

예) 동전을 10번 던졌을때 앞면이 5번 나올 확률 : dbinom(5, 10, 0.5)
    동전을 100번 던졌을때 앞면이 50번 나올 확률 : dbinom(50, 100, 0.5)
예) 동전을 10번 던졌을 때 앞면이 4번 이하로 나올 확률 :  pbinom(4, 10, 0.5)

룰렛게임
s = 강원래드의 수입, 1000명에 대해서 나오는 수입의 분포를 총 B=10000번 시뮬레이션을 통해 알아보자

n <- 1000
b <- 10000
roulette_winnings <- funcion(n){
            x <- sample(c(-1, 1), n, replace = TURE, prob=c(9/19, 10/19))
            sum(X)
            }
S <- replicate(B, roulette_winnings(n))

강원랜드가 돈을 잃을 확률 : 만번중에 음수일 확률
mean(S<0)

이항분포의 정규분포 근사
hist(S, freq=FALSE)
x <- -60, 200, by=1)
lines(x, dnorm(x, mean=mean(S), sd=sd(S)), col="red")


신뢰구간
N <- 1000
B <- 10000
p <- 0.43
inside <- replicate(B, {
            x <- sample(c(0,1), size = N, replace =TRUE, prob = c(-1p, p))
            x_hat <- mean(X)
            se_hat <- sqrt(x_hat * (1-x_hat)/ N)
            between(p, x_hat - 1.96 * se_hat, x_hat + 1.96 * se_hat)    #신뢰구간 추정치 공식
})
mean(inside)


##10-1 순열검정과 P값 (이해가 안된다. 다시 확실히 이해하자)

분할표(contingecy table) : 변수와 관측치를 표시하는 유형의 표

순열검정(permutation test) : 

p-value와 유의수준
p-value : 귀무가설이 참이라는 전제하에 관측한 검정통계량의 값이나 그보다 더 극단적인 값을 얻을 확률
            주어진 기준값(유의수준)보다 작을 경우 검정통계량의 값이 극단적이라고 이야기함
            
대립가설(단측검정과 양측검정) : 특별한 경우가 아니라면 양측검정을 사용
            단측검정은 과학적인 근거나 선행연구 결과가 있을때에만
            예) 신약개발 시 제약회사는 항상 양측검정으로 신약시판 승인함


##10-2 카이제곱검정과 t-검정  (중요! & 어렵다!)


검정통계량의 분포 : 표준정규분포, 카이제곱분포, t-분포를 따르며 카이제곱분포와 t-분포의 경우 자유도를 모수로 가짐
                    자유도가 커지면 두 분포는 정규분포의 모습과 비슷해짐
p-vlaue를 구하기 위해서 귀무가설하에서 검정통계량의 분포를 알아야 하는데 이 분포는 카이제곱분포를 따름

t-분포 : 0을 중심으로 대칭, 꼬리부분이 정규분포와 두터운 모양


##10-3 다중비교와 검정력 (어렵다! 다시듣기!!)

귀무가설이 참인 두번의 가설검정에서 적어도 한번은 p-value가 0.05보다 작을 확률이 거의 10%에 육박
귀무가설의 개수가 10이라면 유의수준 0.05에서 한번이라도 잘못 결론을 내릴확률이 40%

다중검정의 문제 : 연구자들이 데이터를 여러개로 쪼개서 각각에 대한 가설 검정 후 유의미한 결과를 발표할때 생기는 문제

fMRI영상의 voxel사례 : 자극에 따른 뇌 활동의 변화를 검정통계량으로 나타낸 후 가설검정을 실시

Bonferroni 교정 : 평균적으로 몇개의 거짓양성이 발생할 수 있음 
                        ->이 문제를 피하기 위해 유의수준을 일반적 기준인 0.05보다 많이 낮추어야 함
                  가장 보편적인 교정방법
                본페르니 교정을 사용할 경우 상대적으로 귀무가설을 너무 기각하지 않는다는 단점        

오발견율(False Discovery Rate) : 전체기각된 가설검정의 개수 중 잘못 기각한 경우의 비율

제1종의 오류, 제2종의 오류 

검정력은 표본의 개수가 커질수록 증가
효과크기 : 비교하고자 하는 대상의 기대변화량 

p-value에 관한 6가지 원칙(미국통계학회)


##10-4 가설검정의 여러 문제

library(DT)
gfriend.tabl <- matrix(c(20, 19, 33, 34, 30, 27, 22, 22, 22, 32, 23, 16), nrow=2)
dimnames(gfriend.tabl) <- list(sex=c("male", "female" ),member=c("소원", "예린", "은하", "유주", "신비", "엄지"))
datatable(gfrined.tabl)

chisq.test(gfriend.tabl)  #카이제곱 검정을 시행

급성백혈병 사례(biomarker와 다중검정)
(나온 코드는 다시 살펴보기)
if (!requireNamesspace("BiocManager", quietyly = TRUE))
            install.packages("BiocManager")

BoicManager::install("multtest")

library(multtest)
#2표본 t-검정을 유전자별로 실시하고 p값을 구하기
testatat = mt.testatat(golub, golub.cl)
rawp = 2* (1 - pnorm(abs(testat)))
#
adjusted = mt.rawp2adjp(rawp, c("Bonferroni", "BB"))

sum(adjusted$adj[,2]<0.05)

sum(adjusted$adj[,3]<0.05)



##11-1 베이즈 정리 (Bayes Theorem)


사전확률(prior) : 어떤 특정 사건에 관한 선험적 믿음
 
가능도(likelihood) : 주어진 자료를 관측할 확률

사후확률(posterior) : 자료를 추가하여 사전확률을 업데이트한 확률

도핑테스트 결과는 얼마나 믿을 수 있나
기대돗수나무/ 역기대돗수나무

조건부 확률의 이해

오즈(odds)와 가능도비(likelihood ratios)


##11-2 리처드 3세의 유해는 발견되었는가

shrinkage

가능도비의 계산 -> 법정에서의 활용?

베이즈 추론 : 사전확률분포를 가능도를 이용하여 사후확률분포를 계산하는 방식

베타분포


##11-3 네이트 실버와 선거예측

다수준 모형 또는 계측적 모형을 이용하여 여러 가지 여론 조사의 결과를 합쳐서 하나의 예측결과를 제시하는 메타분석 사용

다수준 회귀와 사후층화

베이자안 가설검정에서는 귀무가설이 참인지 여부에 대해서 결론을 내릴 수 있음

베이즈 인자

통계학분야의 3대 진영
빈도주의자(네이먼-피어슨)
피셔리언
베이지안


##11-4 베이지안 계층모형

사례) 00구의 코로나 유병율은?











