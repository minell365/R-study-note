R programming lecture 2021-3 ~

##6-1 두 그룹간 평균비교분석 (t-test)
단일표본의 평균검정
가설1 : 변수의 평균은 10인가? (one sample t-test)
t.test(변수, mu=검정하고자 하는 평균값)

가설2 : ~(a, b)에 따른 평균에 차이가 있는가? (양측검정, two sample t-test) 
      타겟변수(y축 값), 범주형 변수(x축 값, 위에서 a, b)
t.test(타겟변수~범주형변수, data= )
boxplot(타겟변수~범주형변수, boxwex = 0.5, col = c("yellow", "coral"))

단측검정: 기각역이 한쪽에만 있는 경우
      alternative=c("greater") 또는 alternative=c("less")
t.test(타겟변수~범주형변수, data=  , alternative=c("less"))

두 집단의 비모수적 비교검정 : wilcox.test(x, y) 타겟변수가 서열척도(통증, 만족도 등)일때 사용
wilcox.test(타겟변수~범주형변수)


##6-2 짝을 이룬 그룹간 평균비교
paried t-test : t.test(before, after, mu=0, paired=T)
특정 처리(treatment)의 효과를 비교분석 할때 사용, 동일 표본의 before & after 측정
예) 특정 약의 복용 전후 혈압 비교


##6-3 분산분석(ANOVA)
전체분산을 분할하여 어떤 요인의 영향이 유의한지 검정
Factor가 한개일때(one-way ANOVA)
aov(타겟변수~factor)

사후검정 : ANOVA에서 어떤 factor의 유의성이 검정되면 그 다음에 하는 검정
TukeyHSD()
plot(TurkeyHSD())


##7-1 상관분석

cor(변수1, 변수2)

pearson의 상관계수 : cor(옵션없는 경우)
kendall, spearman의 상관계수 : cor(변수1, 변수2, method=c("spearman"))

예) pairs(car1[변수], cex=1, col=as.integer(car1$cyl), pch=19)
                              색을 특정 변수에 넣는 것
상관계수 r 은 0-1 사이의 값. 1에 가까울 수록 강한 상관성

통계치와 그래프 - monkey 데이터 + king kong 한마리 (데이터가 하나 잘 못 들어간 것이 존재할 때)
->상관관계에 대한 해석을 완전히 바꿘 놓을 수 있음


##7-2 선형회귀모형
단순회귀모형 : lm(y변수(=종속변수)~x변수(=독립변수), data= )    linear model -> lm
plot(x축변소, y축변수)
abline : ad line(선을 추가하는 함수)
예) plot(변수, 변수, col=as.integer(car$cyl), pch=19)
    abline(lm(변수~변수), col="red", lwd=2, lty=1)    #best fit linear line

최소자승법 : 예측값과 관측치간의 오차를 최소화 시키는 회귀계수를 추정
회귀식에 의해 설명되는 부분(SSR)과 설명되지 않는 부분(SSE)


##7-3 회귀모형 진단과 평가  -> 컴에서 들어야 함



##8-1 다중회귀분석
데이터 마이닝, 기계학습 표!
타겟변수 값이 주어지는 경우(변수간의 관계) -> 예측, 분류
타겟변수 값이 없는 경우(개체간의 관계) -> 군집, 연관규칙

예측(prediction) -> 회귀분석, 선형모형, 비선형모형
분류(classification) -> 의사결정나무, 서포트벡터머신, 판별분석, 로지스틱회귀모형

autompg 데이터 활용한 연습 -> mpg(연비)를 종속변수(y)값으로, 나머지를 독립변수(x)

lm(y변수~x1+x2+x3, data= )

예) r1 <- lm(mpg ~ disp+hp+wt+accler, data=car)

단계별 방법(stepwise method)
step(모형, directions="both")

다중공선성 -> 독립변수들 사이에 상관관계가 너무 높아서 회귀계수 해석 불가능

분산팽창계수(VIF) -> 다중공선서의 척도
vif(다중회귀모형)

예)vif(lm(mpg ~ disp+hp+wt+accler, data=car)


##8-2 데이터마이닝과 분류

분류(classification)
오분류율 = 오분류 객체수/전체 객체수
교차검증(cross-validation) : n=100 이면 5등분으로 나누어 4등분은 학습데이터로 예측모형을 구성하고, 나머지 5등분 째 데이터로 검증


##8-3 학습데이터와 검증데이터

iris <- read.csv(file="iris.csv")   #150개 데이터
set.seed(100)  #set.seed는 난수 생성 시 처음 시작값을 주어 둥일한 훈련포본 사용, 지정하지 않으면 매번 다른 훈련표본 생성
               #train/test를 2:1로 랜덤 분할(100/50, n=150)
N=nrow(iris)
tr.idx=sample(1:N, size=N*2/3, replace=FALSE)    #tr.idx는 100개의 무작위로 선정된 100개의 데이터 아이디
tr.idx

iris.train <- iris[tr.idx, -5]   #5번째 열의 종속변수를 제외한 100개의 데이터
iris.test <- iris[-tr.idx, -5]   #5번째 열의 종속변수를 제외한 50개의 데이터

trainLables <- iris[tr.idx, 5]
testLables <- iris[-tr.idx, 5]



##9-1 k-인접기법 

최적 k : 교차검증으로 정확도가 높은 k를 선정
장점 : 계산이 단순하고 효율적
단점 : 범주형변수에 대해서는 거리를 계산할 수 없음

kNN을 수행하기 위한 추가 패키지 설치 - class, caret, scales
class : kNN 수행을 위한 패키지
caret : Confusion matrix를 생성하기 위한 패키지
scales : 최적 k 등 그래프를 위한 패키지

iris 데이터 활용
iris <- read.csv(file="iris.csv", stringsAsFactors = TRUE)
set.seed(1000)
n <- nrow(iris)
tr.idx <- sample.int(n, size = round(2/3*n))

iris.train <- iris[tr.idx, -5]   #독립변수 4개를 포함한 100개의 데이터
iris.test <- iris[-tr.idx, -5]   #독립변수 4개를 포함한 50개의 데이터

trainLables <- iris[tr.idx, 5]    #학습데이터의 타겟변수
testLables <- iris[-tr.idx, 5]    #검증데이터의 타겟변수

kNN함수 : kNN(train=학습데이터, test=검증데이터, cl=타겟변수, k= )
예) md1 <- knn(train=iris.train, test=iris.test, cl=trainLabels, k=5)
    md1   #test데이터(50개)들을 예측한 결과가 저장되어 있음

confusionMatrix(md1, testLabels)  #md1=예측값, testLabels=타겟변수의 실제값

md1, testLabel의 유형이 char(문자), factor(범주) 다를때는 오류가 생김, 그래서 처음에 불러올때 stringsAsFactor 해줌

최적 k의 탐색 : 1 to nrow(train_data)/2 (여기서는 1 to 50까지)
accuracy_k <- Null
nnum <- nrow(iris.train)/2
for(kk in c(1:nnum))
{
      set.seed(1234)
      knn_k <- knn(train=iris.train, test=iris.test, cl+trainLabels, k=kk)
      accuracy_k <- c(accuracy_k, sum(knn_k==testLabels)/length(testLabels))
}      

test_k <- data.frame(k=c(1:nnum), accuracy=accuracy_k[c(1:nnum)])
plot(formula=accuracy~k, data=test_k, type="o", ylim=c(0.5, 1), pch=20, col=3, main="validation-optimal k")
with(test_k, test(accuracy~k, labels=k, pos=1, cex=0.7)

min(test_k[test_k$accuracy %in% max(accuracy_k), "k"])

k=7에서 정확도(.98)가 가장 높음

최종 kNN모형(k=7)
md2 <- knn(train=iris.train, test=iris.test, cl=trainLabels, k=7)
confusionMatrix(md2, testLabels)

kNN모형(k=7) 결과 - 그래프
plot(formula = Petal.Lenth ~ Petal.width,
      data=iris.train, 
      col=alpha(c("purple", "blue", "green"), 0.7)[trainLabels],
      main="knn(k=7)")
point(formula = Petal.Lenth ~ Petal.width,
      data=iris.test,
      pch=17,
      cex=1.2,
      col=alpha(c("purple", "blue", "green"), 0.7)[md2])
legend("bottonright",
      c(paste("train", levels(trainLables)), paste("test, levels(testLabels))),
      pch=c(rep(1,3), rep(17,3)),
      col=(c(rep(alpha(c("purple", "blue", "green"), 0.7),2)),
      cex=0.9)
      

##9-2 판별분석1  (이론 내용이 어렵다!!)

-객체를 몇 개의 범주로 분류
-범주들을 가장 잘 구분하는 변수 파악 및 범주간 차이를 가장 잘 표현하느 함수 도출
-의사결정이론 : 선형판별분석, 이차판별분석

-선형판별분석 : 오분류 총 확률 = P{범주 1로 오분류} + P{범주 2로 오분류}

iris <- read.csv("iris.csv", stringsAsFactors = TRUE)
attach(iris)

set.seed(1000)
n <- nrow(iris)
tr.idx <- sample.int(n, size=round(2/3*n))

iris.train <- iris[tr.idx, -5]
iris.train <- iris[-tr.idx, -5]

MASS 패키지 설치
LDA함수 : ida(종속변수 ~ 독립변수, data=학습 데이터 이름, prior=사전 확률)

iris.lda <- ida(Species ~ ., data=train, prior=c(1/3, 1/3, 1/3))
iris.lda

참고) Species ~. 는 Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width 와 같은 의미(독립변수 전체를 의미)
      사전확률(prior probability) : 원인 A가 발생할 확률인 P(A)와 같이 결과가 나타나기 전에 결정되어 있는 확률
      
testpred <- predict(iris.lda, test)

정확도 산정 : 오분류율(검증데이터)
confusionMatrix(testpred$class, testLabels)


##9-3 판별분석2 

선형판별분석 vs. 이차판별분석

이차판별분석(QDA) : 모집단 등분산 검정 -> 분산-공분산 행렬이 범주별로 다른 경우, 이차판별분석을 실시
=> Box's M-test


LDA : 두 범주를 분류하는 선형판별함수, 범주간 동일한 분산-공분산행렬을 가정
QDA : 판별함수가 변수들에 대한 이차함수로 표현, 공분산 행렬이 범주별로 다른 경우

이차판별분석(QDA) 
등분산검정을 위한 패키지 : biotools

library(biotools)
boxM(iris[1:4], iris$Species)

QDA함수 : qda(종속변수 ~ 독립변수, data=학습데이터 이름, prior=사전확률)

iris.qda <- qda(Species ~ ., data=train, prior=c(1/3, 1/3, 1/3))
iris.qda

testpredq <- predict(iris.qda, test)

confusionMatrix(testpredq$class, testLabels)


##10-1 서포트벡터머신

분류모델 중 하나
장점 : 정확도가 상대적으로 좋음, 다양한 데이터(연속형, 범주형) 사용가능
단점 : 해석하기 어려움, 데이터가 많을 때 속도가 걸림

선형 SVM : H와 평행인 두 하이퍼플레인
H1과 H2간의 거리를 최대로 하는 분리 하이퍼플레인을 찾자!

비선형 SVM : 대부분의 패턴은 선형적으로 분리 불가능
비선형 패턴의 입력공간을 선형패턴의 'feature space'로 변환
kernel method로 비선형 경계면 도출

library(e1071)   : e1071은 svm 함수 사용을 위한 패키지
library(caret)   : caret은 confusionMatrix 사용을 위한 패키지

데이터 불러오기, stringsAsFactor=TRUE

svm(y변수 ~ x변수, data= )

m1 <- svm(Species ~., data=iris)
summary(m1)

svm모델에 적용한 예측범주와 실제범주 비교(전체 데이터를 사용한 결과)

x <- iris[, -5]
pred <- predict(m1, x)

y <- iris[, -1]
confusionMatrix(pred, y)

시각화
plot(ma, iris, Petal.Width~Petal.Length, slice=list(Sepal.Width=3, 

Petal.Width~Petal.Length가 가장 중요한 변수라는 것을 이미 알고 있는 상황)
 

##10-2 서포트벡터머신2

kernel 함수 

커널(kernel)이란 : 저차원을 고차원으로 변환시켜 주는 함수, 변환을 통해 X에 대한 새로운 특징을 추출할 수 있도록 함

set.seed(1000)
N=norw(iris)
tr.idx=sample(1:N, size=n=*2/3)

iris.train <- iris[tr.idx,]
iris.train <- iris[-tr.idx,]

m1 <- svm(Species~., data=train)
summary(m1)

m2 <- svm(Species~., data=train.kernel="Polynomianl")
summary(m2)

m3 <- svm(Species~., data=train.kernel="sigmoid")
summary(m3)

각 kernel 함수에 따른 결과 비교, 각 함수마다 오분류 되는 것이 다름
pred11 <- predict(m1, test)   #m1 자리에 m2, m3 차례로 입력하여 결과값 확인
confusionMatrix(pred11, test$Species)


m4 <- svm(formula = Species~., data=train.kernel="liner")
summary(m4)



##10-3 서포트벡터머신3

library(e1071)
library(caret)

cancer <- read.csv("cancer.csv", stringsAsFactor = TRUE)
head(cancer, 10)

cancer <- cancer[. names(cancer) != "X1"]   #첫번째 컬럼인 ID넘버는 필요없는 feature이므로 제거
attach(cancer)

N=nrow(cancer)
set.seed(998)

tr.idx=sample(1:n, size=N*2/3, replace=FALSE)  #데이터 분할, 학습데이터 2/3, 검증데이터 1/3
train <- cancer[tr.idx,]
test <- cancer[-tr.idx,]

kernel 함수에 따른 서포트벡터머신
m1 <- svm(Y ~., data=train)   #radial
summary(m1)

m2 <- svm(Y ~., data=train, kernel="polymomial")   #polymomial
summary(m2)

m3 <- svm(Y ~., data=train, kernel="sigmoid")   #sigmoid
summary(m3)

m4 <- svm(Y ~., data=train, kernel="linear")   #linear
summary(m4)

정확도 측정 #m1~m4까지 각 측정
pred11 <- predict(m1, test)
confusionMatrix(pred11, test$Y)


##11-1 의사결정나무1

의사결정나무 : 의사결정 규칙을 나무형태로 분류해 나가는 분석 기법, 기계학습 중 하나
               분석과정이 직관적이고 이해하기 쉬움, 연속형/범주형 변수 모두 사용할 수 있음, 분지 규칙은 불순도를 최소화 시킴
             
tree형성(Growing tree)
tree가지치기(Pruning tree)
최적 tree로 분류(Classification)

의사결정나무 실행 피키지 : tree(그외 rpart, party 패키지)
library(tree)
library(caret)

iris <- read.csv("iris.csv", stringsAsFactors = TRUE)
set.seed(1000)
N <- nrow(iris)
tr.idx <- sample91:n, size=N*2/3, replace=FALSE)

train <- iris[tr.idx,]
test <- iris[-tr.idx,]

treemod <- tree(Species ~., data=train)
treemod
plot(treemod)   #의사결정나무 분지를 그림으로 표현
text(treemod, cex=1.5)   #cex : 폰트사이즈

tree의 결과(*는 터미널노드) : 마디 6에서는 더 이상 분지할 필요 없음

최적 tree모형을 위한 가지치기(pruning) : cv.tree(tree모형결과, FUN=)
결과에서 교차검증오차(deviance)의 값이 최소가 되는 노드 수 선택

cv.trees <- cv.tree(treemod, FUN=prune.misclass)
cv.trees
plot(cv.trees)

par(mfrow=c(1,2))
plot(cv.trees$size, cv.trees$dev, type="b")
plot(cv.trees$k, cv.trees$dev, type="b")

pruning(가지치기) : cv.tree함수를 이용하여 최적 터미널노드를 탐색

prune.trees <- prune.misclass(treemod, bext=3)  #prune.trees는 최종모형의 이름(최종터미널노드=3)
plot(prune.trees)
text(prune.trees, pretty=0, cex=1.5)

의사결정나무결과 정확도 : test data에 대한 정확도
treepred <- predict(prune.trees, test, type='class')
confusionMatrix(treepred, test$Species)



##11-2 의사결정나무2

의사결정나무 실행 패키지 : rpart패키지 (tree패키지 외 사용)

library(rpart)
library(party)
library(caret)

의사결정나무 함수 : rpart(종속변수 ~ x1+x2+x3+x4, data= )
cl1 <- rpart(Species ~., data=train)
plot(cl1)
text(cl1, cex=1)

rpart패기지에서의 최적 트리모델(cp(compexity parameter)비교)
printcp에서 xerror(cross validation error)의 값이 최소가 되는 트리를 선택
printcp(cl1)
plotcp(cl1)

rpart를 사용한 최종 tree모형
pcl1 <- prune(cl1, cp=li1$cptable[which.min(cl1$cptalbe[, "xerror"]), "CP"])
plot(pcl1)
text(pcl1)

pred2 <- predict(pcl1, test, type='class')
confusionMatrix(pred2, test$Species)

의사결정나무 실행 피키지 : party 패키지
ctree(종속변소 ~ x1+x2+x3+x4, data= )
partymod <- ctree(Species ~., data=train)
plot(partymod)
partymod

partypred <- predict(partymod, test)
confusionMatrix(partypred, test$Species)


























