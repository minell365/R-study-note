R programming lecture 2021-3 ~

##6-1 두 그룹간 평균비교분석 (t-test)
단일표본의 평균검정
가설1 : 변수의 평균은 10인가? (one sample t-test)
t.test(변수, mu=검정하고자 하는 평균값)

가설2 : ~(a, b)에 따른 평균에 차이가 있는가? (양측검정, two sample t-test) 
      타겟변수(y축 값), 범주형 변수(x축 값, 위에서 a, b)
t.test(타겟변수~범주형변수, data= )
boxplot(타겟변수~범주형변수, boxwex = 0.5, col = c("yellow", "coral"))

단측검정: 기각역이 한쪽에만 있는 경우
      alternative=c("greater") 또는 alternative=c("less")
t.test(타겟변수~범주형변수, data=  , alternative=c("less"))

두 집단의 비모수적 비교검정 : wilcox.test(x, y) 타겟변수가 서열척도(통증, 만족도 등)일때 사용
wilcox.test(타겟변수~범주형변수)


##6-2 짝을 이룬 그룹간 평균비교
paried t-test : t.test(before, after, mu=0, paired=T)
특정 처리(treatment)의 효과를 비교분석 할때 사용, 동일 표본의 before & after 측정
예) 특정 약의 복용 전후 혈압 비교


##6-3 분산분석(ANOVA)
전체분산을 분할하여 어떤 요인의 영향이 유의한지 검정
Factor가 한개일때(one-way ANOVA)
aov(타겟변수~factor)

사후검정 : ANOVA에서 어떤 factor의 유의성이 검정되면 그 다음에 하는 검정
TukeyHSD()
plot(TurkeyHSD())


##7-1 상관분석

cor(변수1, 변수2)

pearson의 상관계수 : cor(옵션없는 경우)
kendall, spearman의 상관계수 : cor(변수1, 변수2, method=c("spearman"))

예) pairs(car1[변수], cex=1, col=as.integer(car1$cyl), pch=19)
                              색을 특정 변수에 넣는 것
상관계수 r 은 0-1 사이의 값. 1에 가까울 수록 강한 상관성

통계치와 그래프 - monkey 데이터 + king kong 한마리 (데이터가 하나 잘 못 들어간 것이 존재할 때)
->상관관계에 대한 해석을 완전히 바꿘 놓을 수 있음


##7-2 선형회귀모형
단순회귀모형 : lm(y변수(=종속변수)~x변수(=독립변수), data= )    linear model -> lm
plot(x축변소, y축변수)
abline : ad line(선을 추가하는 함수)
예) plot(변수, 변수, col=as.integer(car$cyl), pch=19)
    abline(lm(변수~변수), col="red", lwd=2, lty=1)    #best fit linear line

최소자승법 : 예측값과 관측치간의 오차를 최소화 시키는 회귀계수를 추정
회귀식에 의해 설명되는 부분(SSR)과 설명되지 않는 부분(SSE)


##7-3 회귀모형 진단과 평가  -> 컴에서 들어야 함



##8-1 다중회귀분석
데이터 마이닝, 기계학습 표!
타겟변수 값이 주어지는 경우(변수간의 관계) -> 예측, 분류
타겟변수 값이 없는 경우(개체간의 관계) -> 군집, 연관규칙

예측(prediction) -> 회귀분석, 선형모형, 비선형모형
분류(classification) -> 의사결정나무, 서포트벡터머신, 판별분석, 로지스틱회귀모형

autompg 데이터 활용한 연습 -> mpg(연비)를 종속변수(y)값으로, 나머지를 독립변수(x)

lm(y변수~x1+x2+x3, data= )

예) r1 <- lm(mpg ~ disp+hp+wt+accler, data=car)

단계별 방법(stepwise method)
step(모형, directions="both")

다중공선성 -> 독립변수들 사이에 상관관계가 너무 높아서 회귀계수 해석 불가능

분산팽창계수(VIF) -> 다중공선서의 척도
vif(다중회귀모형)

예)vif(lm(mpg ~ disp+hp+wt+accler, data=car)


##8-2 데이터마이닝과 분류

분류(classification)
오분류율 = 오분류 객체수/전체 객체수
교차검증(cross-validation) : n=100 이면 5등분으로 나누어 4등분은 학습데이터로 예측모형을 구성하고, 나머지 5등분 째 데이터로 검증


##8-3 학습데이터와 검증데이터

iris <- read.csv(file="iris.csv")   #150개 데이터
set.seed(100)  #set.seed는 난수 생성 시 처음 시작값을 주어 둥일한 훈련포본 사용, 지정하지 않으면 매번 다른 훈련표본 생성
               #train/test를 2:1로 랜덤 분할(100/50, n=150)
N=nrow(iris)
tr.idx=sample(1:N, size=N*2/3, replace=FALSE)    #tr.idx는 100개의 무작위로 선정된 100개의 데이터 아이디
tr.idx

iris.train <- iris[tr.idx, -5]   #5번째 열의 종속변수를 제외한 100개의 데이터
iris.test <- iris[-tr.idx, -5]   #5번째 열의 종속변수를 제외한 50개의 데이터

trainLables <- iris[tr.idx, 5]
testLables <- iris[-tr.idx, 5]



##9-1 k-인접기법 

최적 k : 교차검증으로 정확도가 높은 k를 선정
장점 : 계산이 단순하고 효율적
단점 : 범주형변수에 대해서는 거리를 계산할 수 없음

kNN을 수행하기 위한 추가 패키지 설치 - class, caret, scales
class : kNN 수행을 위한 패키지
caret : Confusion matrix를 생성하기 위한 패키지
scales : 최적 k 등 그래프를 위한 패키지

iris 데이터 활용
iris <- read.csv(file="iris.csv", stringsAsFactors = TRUE)
set.seed(1000)
n <- nrow(iris)
tr.idx <- sample.int(n, size = round(2/3*n))

iris.train <- iris[tr.idx, -5]   #독립변수 4개를 포함한 100개의 데이터
iris.test <- iris[-tr.idx, -5]   #독립변수 4개를 포함한 50개의 데이터

trainLables <- iris[tr.idx, 5]    #학습데이터의 타겟변수
testLables <- iris[-tr.idx, 5]    #검증데이터의 타겟변수

kNN함수 : kNN(train=학습데이터, test=검증데이터, cl=타겟변수, k= )
예) md1 <- knn(train=iris.train, test=iris.test, cl=trainLabels, k=5)
    md1   #test데이터(50개)들을 예측한 결과가 저장되어 있음

confusionMatrix(md1, testLabels)  #md1=예측값, testLabels=타겟변수의 실제값

md1, testLabel의 유형이 char(문자), factor(범주) 다를때는 오류가 생김, 그래서 처음에 불러올때 stringsAsFactor 해줌

최적 k의 탐색 : 1 to nrow(train_data)/2 (여기서는 1 to 50까지)
accuracy_k <- Null
nnum <- nrow(iris.train)/2
for(kk in c(1:nnum))
{
      set.seed(1234)
      knn_k <- knn(train=iris.train, test=iris.test, cl+trainLabels, k=kk)
      accuracy_k <- c(accuracy_k, sum(knn_k==testLabels)/length(testLabels))
}      

test_k <- data.frame(k=c(1:nnum), accuracy=accuracy_k[c(1:nnum)])
plot(formula=accuracy~k, data=test_k, type="o", ylim=c(0.5, 1), pch=20, col=3, main="validation-optimal k")
with(test_k, test(accuracy~k, labels=k, pos=1, cex=0.7)

min(test_k[test_k$accuracy %in% max(accuracy_k), "k"])

k=7에서 정확도(.98)가 가장 높음

최종 kNN모형(k=7)
md2 <- knn(train=iris.train, test=iris.test, cl=trainLabels, k=7)
confusionMatrix(md2, testLabels)

kNN모형(k=7) 결과 - 그래프
plot(formula = Petal.Lenth ~ Petal.width,
      data=iris.train, 
      col=alpha(c("purple", "blue", "green"), 0.7)[trainLabels],
      main="knn(k=7)")
point(formula = Petal.Lenth ~ Petal.width,
      data=iris.test,
      pch=17,
      cex=1.2,
      col=alpha(c("purple", "blue", "green"), 0.7)[md2])
legend("bottonright",
      c(paste("train", levels(trainLables)), paste("test, levels(testLabels))),
      pch=c(rep(1,3), rep(17,3)),
      col=(c(rep(alpha(c("purple", "blue", "green"), 0.7),2)),
      cex=0.9)
      
      







